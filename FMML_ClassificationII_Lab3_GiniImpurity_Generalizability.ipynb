{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gopathotisrinadh21/FMML_LAB_ASSESSMENTS/blob/main/FMML_ClassificationII_Lab3_GiniImpurity_Generalizability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK5nkETWlnfU"
      },
      "source": [
        "# Lab 3\n",
        "# Classification II : Information Metrics and generalizability of Decision Trees\n",
        "\n",
        "```\n",
        "Module Coordinator : Arohi Srivastav\n",
        "```\n",
        "\n",
        "### RECAP:\n",
        "\n",
        "In the last lab, we learnt:\n",
        "\n",
        "- What is a decision tree and how is a DT used to made a prediction.\n",
        "- How the complexity of tree effects its performance. (An example where increasing the complexity improves the performance.)\n",
        "- Notion of Entropy and Information Gain and how they can be used to create a tree.\n",
        "- Nature of decision boundaries made by DTs.\n",
        "\n",
        "\n",
        "### In this lab:\n",
        "\n",
        "- Introduction to Gini Index and how can it be used to create decision tree.\n",
        "- Curse of Overfitting and how it affects decision trees.\n",
        "- Application of Decision Trees on a real dataset and further experiments.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfPd1_dZKU2m"
      },
      "source": [
        "---\n",
        "\n",
        "## Gini Impurity:\n",
        "\n",
        "Gini Impurity is another metric like Entropy which can be used to score a group's homogenity. \n",
        "A group's Gini Impurity is given by:\n",
        "\n",
        "$$ \\text{Gini Index} = 1 - \\sum_{i=1}^{c} p_i^2 $$\n",
        "\n",
        "Whichever division leads to minimum impurity among the divided class is chosen to be the split at that stage.\n",
        "\n",
        "`Impurity of a division =  Weighted sum of the impurity of the subgroups made after the division`\n",
        "\n",
        "Among Gini impurity and Information Gain, there isn't a clear cut better method of developing a decision tree. Though many a times Gini Impurity is the preferred method since it is computationally lesser expensive.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydOB8-b4k5hU",
        "outputId": "7ab93fe4-b72c-4795-9f0b-63661e95670a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "#Importing the necessary packages\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ad549076d7d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menable_iterative_imputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIterativeImputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'plot_confusion_matrix' from 'sklearn.metrics' (/usr/local/lib/python3.9/dist-packages/sklearn/metrics/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Wkpt7Mg5kGe"
      },
      "source": [
        "def performExperiment(trainSet : tuple, testSet : tuple, max_depth : int = None, feature_names : list = None, class_names : list = None, criterion = \"gini\", min_samples_split : int = 2 , min_samples_leaf = 1, drawTree = (8,6)):\n",
        "  #Importing the Decision tree classifier from sklearn:\n",
        "\n",
        "  clf = tree.DecisionTreeClassifier(max_depth = max_depth, \\\n",
        "                                    criterion = criterion,\\\n",
        "                                    min_samples_split = min_samples_split,\\\n",
        "                                    min_samples_leaf = min_samples_leaf,\\\n",
        "                                    splitter = \"best\",\\\n",
        "                                    random_state = 0,\\\n",
        "                                    )\n",
        "  X_train, y_train = trainSet\n",
        "  X_test, y_test = testSet\n",
        "\n",
        "  clf = clf.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = clf.predict(X_test)\n",
        "\n",
        "  print(\"Accuracy of the decision tree on the test set: \\n\\n{:.3f}\\n\\n\".format(accuracy_score(y_pred, y_test)))\n",
        "\n",
        "  print(\"The confusion matrix is : \")\n",
        "  \n",
        "  fig, ax = plt.subplots(figsize=(3, 3))\n",
        "  plot_confusion_matrix(clf, X_test, y_test, display_labels=class_names, ax=ax)\n",
        "  plt.show()\n",
        "\n",
        "  if drawTree:\n",
        "    print(\"Here is a diagram of the tree created to evaluate each sample:\")\n",
        "    fig, ax = plt.subplots(figsize=drawTree)\n",
        "    imgObj = tree.plot_tree(clf, filled=True, ax=ax, feature_names = feature_names, class_names = class_names, impurity=False, proportion=True, rounded=True, fontsize = 10)\n",
        "    plt.show()\n",
        "\n",
        "def returnAccuracy(trainSet : tuple, testSet : tuple, max_depth : int = None, feature_names : list = None, class_names : list = None, criterion = \"gini\", min_samples_split : int = 2 , min_samples_leaf = 1):\n",
        "  clf = tree.DecisionTreeClassifier(max_depth = max_depth, \\\n",
        "                                    criterion = criterion,\\\n",
        "                                    min_samples_split = min_samples_split,\\\n",
        "                                    min_samples_leaf = min_samples_leaf,\\\n",
        "                                    splitter = \"best\",\\\n",
        "                                    random_state = 0,\\\n",
        "                                    \n",
        "                                    )\n",
        "  X_train, y_train = trainSet\n",
        "  X_test, y_test = testSet\n",
        "\n",
        "  clf = clf.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = clf.predict(X_test)\n",
        "\n",
        "  return accuracy_score(y_pred, y_test)\n",
        "\n",
        "def giveAnExample(n : int):\n",
        "  performExperiment((X_train, y_train),  (X_test, y_test), feature_names = iris[\"feature_names\"], class_names = iris[\"target_names\"], max_depth = n)\n",
        "\n",
        "def plotDecisionBoundary(X, y, pair, clf):\n",
        "  x_min, x_max = X[:, pair[0]].min() - 1, X[:, pair[0]].max() + 1\n",
        "  y_min, y_max = X[:, pair[1]].min() - 1, X[:, pair[1]].max() + 1\n",
        "  xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
        "                      np.arange(y_min, y_max, 0.1))\n",
        "  \n",
        "  y_pred = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "  y_pred = y_pred.reshape(xx.shape)\n",
        "  plt.figure(figsize=(5,4))\n",
        "  plt.contourf(xx, yy, y_pred, alpha=0.4)\n",
        "  plt.scatter(X[:, pair[0]], X[:, pair[1]], c = y, s = 50, edgecolor='k')\n",
        "  # plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSsre0KN5C-H"
      },
      "source": [
        "Let us create a synthetic dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyH1HwtawwNk"
      },
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "ar = np.vstack(     [\\\n",
        "                    np.random.multivariate_normal(np.array([1, 1]), 1.5 * np.array([[2, -1], [-1, 2.0]]), size = 50, ),\\\n",
        "                    np.random.multivariate_normal(np.array([3, 3]), 2 * np.array([[0.75, -0.5], [-0.5, 0.75]]), size = 50, )\n",
        "                    ]\\\n",
        "              )\n",
        "\n",
        "testAr = np.vstack(   [\\\n",
        "                      np.random.multivariate_normal(np.array([1, 1]), np.array([[0.5, -0.25], [-0.25, 0.5]]), size = 500, ),\\\n",
        "                      np.random.multivariate_normal(np.array([3, 3]), np.array([[0.75, -0.5], [-0.5, 0.75]]), size = 500, )\n",
        "                      ]\\\n",
        "                  )\n",
        "testy = np.array([0] * int((testAr.shape[0]/2)) + [1] * int((testAr.shape[0]/2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evClB9vYxIOY"
      },
      "source": [
        "plt.figure(figsize=(5,4))\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.scatter(ar[:, 0], ar[:, 1], c = np.array([\"r\"] * int((ar.shape[0]/2)) + [\"b\"] * int((ar.shape[0]/2))), )\n",
        "plt.title(\"Noisy Training Data\")\n",
        "plt.xlim((-3, 8))\n",
        "plt.ylim((-3, 8))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.title(\"Real pattern of information\")\n",
        "plt.scatter(testAr[:, 0], testAr[:, 1], c = np.array([\"r\"] * int((testAr.shape[0]/2)) + [\"b\"] * int((testAr.shape[0]/2))), )\n",
        "\n",
        "plt.xlim((-3, 8))\n",
        "plt.ylim((-3, 8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfXScFLH-loQ"
      },
      "source": [
        "X = ar\n",
        "y = np.array([0] * int((ar.shape[0]/2)) + [1] * int((ar.shape[0]/2)))\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "fro, to = 1, 15\n",
        "plt.plot(range(fro, to), [returnAccuracy((X, y), (testAr, testy), max_depth = i) for i in range(fro, to)], \"b.-\", linewidth=0.5)\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Depth of the tree\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMekSS9ExeWQ"
      },
      "source": [
        "def boundaryExp(d) :\n",
        "\n",
        "  clf = tree.DecisionTreeClassifier(random_state = 0, max_depth = d)\n",
        "  pair = [0, 1]\n",
        "  clf.fit(X[:, pair], y)\n",
        "  print(\"Depth = {}\".format(d))\n",
        "  plotDecisionBoundary(X, y, pair, clf)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "_ = [boundaryExp(i) for i in [1, 2, 4, 8]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mZJ_nuAQIHV"
      },
      "source": [
        "plt.style.use(\"default\")\n",
        "performExperiment((X, y), (testAr, testy), max_depth = 2, drawTree = (8,4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJP-iW5hz4D0"
      },
      "source": [
        "plt.style.use(\"default\")\n",
        "performExperiment((X, y), (testAr, testy), max_depth = 4, drawTree= (12, 8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ1Q39yh9ry1"
      },
      "source": [
        "plt.style.use(\"default\")\n",
        "performExperiment((X, y), (testAr, testy), max_depth = 8, drawTree = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9hb0t5e2M0M"
      },
      "source": [
        "Now that we have looked at the curse of overfitting and its consequence on the test accuracy, let us try to delve deeper and try to understand that why is it such a serious issue especially for Decision Tree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPVQHxyv4zDS"
      },
      "source": [
        "---\n",
        "\n",
        "## Finding Pattern out of nowhere?\n",
        "\n",
        "\n",
        "In the following cell we are generating a series of random numbers from a 2-D uncorrelated Gaussian distribution. And then we randomly assign a class to each of these datapoints. i.e There exists no real pattern in the dataset and we are simply giving them a class arbitrarily.\n",
        "\n",
        "Now let us see how out decision tree does on this when the same set is used as the test set as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGWQcvqr2pAq"
      },
      "source": [
        "SIZE_DECOY = 100\n",
        "np.random.seed(0)\n",
        "simpleDat = np.random.multivariate_normal((0, 0), [[2, 0], [0, 2]], size = SIZE_DECOY)\n",
        "decoyY = np.random.randint(0, 2, size = SIZE_DECOY)\n",
        "COLS = [\"red\", \"blue\"]\n",
        "plt.style.use(\"seaborn\")\n",
        "plt.scatter(simpleDat[:, 0], simpleDat[:, 1], c = [COLS[i] for i in decoyY])\n",
        "plt.xlim((-5, 5)), plt.ylim((-5, 5))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aQ99h6W6KHy"
      },
      "source": [
        "\n",
        "clf = tree.DecisionTreeClassifier(random_state = 0)\n",
        "pair = [0, 1]\n",
        "clf.fit(simpleDat[:, pair], decoyY)\n",
        "plt.style.use(\"default\")\n",
        "plotDecisionBoundary(simpleDat, decoyY, pair, clf)\n",
        "plt.show()\n",
        "\n",
        "performExperiment((simpleDat, decoyY), (simpleDat, decoyY), drawTree=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x2P_RMy7Wg4"
      },
      "source": [
        "Wow, we see that our decision tree is able to predict the values in our train set with $100\\%$  accuracy!\n",
        "\n",
        "That is not a surprise if we pay attention to the nature of Decision Trees. They are in fact capable of **adapting completely to any discrete binary function that exists**. This behavious can be explained using the point they can be seen as nothing but piecewise function definition itself.\n",
        "\n",
        "Does that mean that our decision tree has learnt something? Let us explore by testing it on another set of points taken from the same distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91wSCnLH83hH"
      },
      "source": [
        "SIZE_DECOY = 100\n",
        "np.random.seed(1)\n",
        "testSimpleDat = np.random.multivariate_normal((0, 0), [[2, 0], [0, 2]], size = SIZE_DECOY)\n",
        "testDecoyY = np.random.randint(0, 2, size = SIZE_DECOY)\n",
        "performExperiment((simpleDat, decoyY), (testSimpleDat, testDecoyY), drawTree=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vleeyJ2X-A2m"
      },
      "source": [
        "We infact see that our decision tree has not learnt much since its accuracy is $48\\%$ on a set that it hasn't seen before which is to be expected since there are only 2 classes to predict."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnNK8FOZY-nX"
      },
      "source": [
        "---\n",
        "\n",
        "## Experiment on Titanic Dataset\n",
        "\n",
        "`Reference Dataset taken from: https://www.kaggle.com/c/titanic/data`\n",
        "\n",
        "\n",
        "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
        "\n",
        "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
        "\n",
        "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
        "\n",
        "Our task in rest of today's lab is to use decision trees to predict if a person would be able to survive or not. \n",
        "\n",
        "<table>\n",
        "<tbody>\n",
        "<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n",
        "<tr>\n",
        "<td>survival</td>\n",
        "<td>Survival</td>\n",
        "<td>0 = No, 1 = Yes</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>pclass</td>\n",
        "<td>Ticket class</td>\n",
        "<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>sex</td>\n",
        "<td>Sex</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Age</td>\n",
        "<td>Age in years</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>sibsp</td>\n",
        "<td># of siblings / spouses aboard the Titanic</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>parch</td>\n",
        "<td># of parents / children aboard the Titanic</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>ticket</td>\n",
        "<td>Ticket number</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>fare</td>\n",
        "<td>Passenger fare</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>cabin</td>\n",
        "<td>Cabin number</td>\n",
        "<td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>embarked</td>\n",
        "<td>Port of Embarkation</td>\n",
        "<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n",
        "</tr>\n",
        "</tbody>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlIrzXfzV-Si",
        "outputId": "1c9d12e7-7a65-48fe-bf77-3500a3a15ef1"
      },
      "source": [
        "import os\n",
        "os.system(\"wget https://raw.githubusercontent.com/Foundations-in-Modern-Machine-Learning/course-contents/main/Classification2/data/titanic/train.csv\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il3ExmG9bSii",
        "outputId": "a9b17e1d-8f9e-4eba-dbc8-11a0dd48ba36"
      },
      "source": [
        "import os\n",
        "os.listdir()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'train.csv', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW1IGKBIbVR9"
      },
      "source": [
        "import pandas as pd\n",
        "trainDf = pd.read_csv(\"train.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU5JigCTjnc8",
        "outputId": "194aa946-3fc1-487e-d234-60eaf74b3bd0"
      },
      "source": [
        "# Preprocessing:\n",
        "\n",
        "trainDf.columns"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
              "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "id": "8bYnNT0emiHY",
        "outputId": "0f487aa4-fe3a-4ad0-bf21-b49f40ffaf4b"
      },
      "source": [
        "trainDf"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     PassengerId  Survived  Pclass  \\\n",
              "0              1         0       3   \n",
              "1              2         1       1   \n",
              "2              3         1       3   \n",
              "3              4         1       1   \n",
              "4              5         0       3   \n",
              "..           ...       ...     ...   \n",
              "886          887         0       2   \n",
              "887          888         1       1   \n",
              "888          889         0       3   \n",
              "889          890         1       1   \n",
              "890          891         0       3   \n",
              "\n",
              "                                                  Name     Sex   Age  SibSp  \\\n",
              "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                             Allen, Mr. William Henry    male  35.0      0   \n",
              "..                                                 ...     ...   ...    ...   \n",
              "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
              "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
              "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
              "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
              "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
              "\n",
              "     Parch            Ticket     Fare Cabin Embarked  \n",
              "0        0         A/5 21171   7.2500   NaN        S  \n",
              "1        0          PC 17599  71.2833   C85        C  \n",
              "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3        0            113803  53.1000  C123        S  \n",
              "4        0            373450   8.0500   NaN        S  \n",
              "..     ...               ...      ...   ...      ...  \n",
              "886      0            211536  13.0000   NaN        S  \n",
              "887      0            112053  30.0000   B42        S  \n",
              "888      2        W./C. 6607  23.4500   NaN        S  \n",
              "889      0            111369  30.0000  C148        C  \n",
              "890      0            370376   7.7500   NaN        Q  \n",
              "\n",
              "[891 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd2be0cc-5463-4d63-85c3-f714b47e5316\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd2be0cc-5463-4d63-85c3-f714b47e5316')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cd2be0cc-5463-4d63-85c3-f714b47e5316 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cd2be0cc-5463-4d63-85c3-f714b47e5316');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvQhY6OQjrUa"
      },
      "source": [
        "for idx, row in trainDf.iterrows():\n",
        "  if row[\"Sex\"] == \"female\":\n",
        "    trainDf.at[idx, \"Sex\"] = 0\n",
        "  else:\n",
        "    trainDf.at[idx, \"Sex\"] = 1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juYt8Vbybd7q"
      },
      "source": [
        "# Since we are only exploring, lets make a validation set out of trainDf:\n",
        "\n",
        "trainSet, testSet = train_test_split(trainDf, random_state = 0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJwHF3RtbnUe"
      },
      "source": [
        "def relevantInfo(df):\n",
        "  X = df.iloc[:, [2, 4, 5, 6, 7, 9]]\n",
        "  y = df.iloc[:, 1]\n",
        "\n",
        "  #Preprocessing to handle the missing data using a regressor\n",
        "  imp = IterativeImputer(max_iter = 10, random_state=0)\n",
        "  imp.fit(X)\n",
        "  newDf = imp.transform(X)\n",
        "\n",
        "  return newDf , y.to_numpy()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_fGAEAte4mY",
        "outputId": "25229a9a-f007-430b-f4b5-1b42b962d8d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "trainX, trainy = relevantInfo(trainSet)\n",
        "testX, testy = relevantInfo(testSet)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-dde18bfd2303>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelevantInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelevantInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-0406f2d206d4>\u001b[0m in \u001b[0;36mrelevantInfo\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m#Preprocessing to handle the missing data using a regressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mimp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIterativeImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mnewDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'IterativeImputer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o7P5oIle5q6"
      },
      "source": [
        "performExperiment((trainX, trainy), (testX, testy), max_depth = 3, feature_names=[trainDf.columns[i] for i in [2, 4, 5, 6, 7, 9]], class_names=[\"Died\", \"Survived\"], drawTree=(20, 6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joTfTocTWGT-"
      },
      "source": [
        "MAX_DEPTH = 6 #@param {type: \"slider\", min: 2, max: 10}\n",
        "CRITERION =  \"gini\" #@param [\"gini\", \"entropy\"]\n",
        "MIN_SAMPLES_TO_SPLIT = 2 #@param {type:\"slider\", min:2, max:20, step:2}\n",
        "MIN_SAMPLES_IN_LEAF = 1 #@param {type: \"slider\", min: 1, max: 50}\n",
        "\n",
        "plt.style.use(\"default\")\n",
        "performExperiment((trainX, trainy),\\\n",
        "                  (testX, testy),\\\n",
        "                  max_depth = MAX_DEPTH,\\\n",
        "                  feature_names=[trainDf.columns[i] for i in [2, 4, 5, 6, 7, 9]],\\\n",
        "                  class_names=[\"Died\", \"Survived\"],\\\n",
        "                  min_samples_split = MIN_SAMPLES_TO_SPLIT,\\\n",
        "                  min_samples_leaf = MIN_SAMPLES_IN_LEAF,\\\n",
        "                  drawTree=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzbrk2F-sjsd"
      },
      "source": [
        "Let us iterate over all the possible values for depth to find the most optimum depth possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsScfldthNJ9"
      },
      "source": [
        "plt.style.use(\"seaborn\")\n",
        "plt.figure(figsize=(8,6))\n",
        "fro, to = 1, 15\n",
        "plt.plot(range(fro, to), [returnAccuracy((trainX, trainy), (testX, testy), max_depth = i, min_samples_leaf=3, min_samples_split=6, criterion=\"entropy\") for i in range(fro, to)], \"g.-\", linewidth=0.5)\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Depth of the tree\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbCQmV3T-21T"
      },
      "source": [
        "---\n",
        " \n",
        "End of Lab 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3_ap9f4-4r0"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}